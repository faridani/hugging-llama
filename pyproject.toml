[build-system]
requires = ["setuptools>=67", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "hugging-llama"
version = "0.1.0"
description = "Local Ollama compatible server built on Hugging Face transformers"
authors = [{name = "Mark Faridani", email = "faridani@gmail.com"}]
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
  "accelerate",
  "fastapi",
  "httpx",
  "jsonschema",
  "prometheus-client",
  "sentence-transformers",
  "transformers",
  "torch",
  "uvicorn[standard]",
]

[project.optional-dependencies]
dev = [
  "mypy",
  "pre-commit",
  "pytest",
  "ruff",
  "coverage",
  "coverage-badge",
  "types-jsonschema",
]

[project.scripts]
hugging-llama = "hugging_llama.cli:main"

[tool.setuptools.packages.find]
where = ["src"]

[tool.ruff]
line-length = 120

[tool.ruff.lint]
select = ["E", "F", "I", "B", "UP", "S"]
per-file-ignores = {"tests/**/*" = ["S101"]}

[tool.mypy]
python_version = "3.9"
strict = false
warn_unused_configs = true

[[tool.mypy.overrides]]
module = [
  "accelerate",
  "accelerate.*",
  "torch",
  "torch.*",
  "transformers",
  "transformers.*",
]
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests"]
pythonpath = ["src"]
